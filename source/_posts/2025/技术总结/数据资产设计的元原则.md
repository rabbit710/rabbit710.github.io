---
title: 数据资产设计的元原则
subtitle: 
date: 2025-03-17
categories: 
tags: 
---


# 思考的背景
最近在思考业务数据的成本优化问题。我想，业务的数据架构必然存在一个相对最完美的范式；但实际工作中的烟囱式开发，本质上是凭借开发本能、没有理论的模式，必然会导致成本浪费（开发、维护、存储等成本项）。因此，将目前现实的数据架构，转变为接近完美的、充分设计的数据架构，必然会带来成本的节约。

以上过程可以类比从市场经济到计划经济的转变。


# 数据架构的评价标准
首先要找到评价标准，也就是，业务的数据架构是否完美，有什么评价标准？有人说，数据和业务强绑定，要从业务视角判断数据架构是否优秀；我认为这是谬论。一旦技术和业务关联在一起分析，很多地方就说不清道不明了；复杂度可以拆解为业务复杂度和技术复杂度，对于开发者来说前者无法改变，我们只需要评估和优化后者。

最优秀的数据架构本质上就是在业务需求、技术复杂度、成本三者之间找到最优平衡点。

那么优秀或者完美的数据架构，存在什么标准？回顾以前的工作，我可以列举出这些：
- 数据资产的复用性要很高，烟囱式开发尽量少
- 数据指标开发要快（用户想要的数据，马上就能给）
- 成本要低
- 数据血缘简单、清晰
- 离线和实时的一致性，多个业务系统的一致性要保障
- 等等

标准似乎很多，但看起来没什么头绪；它们都是从日常搬砖中简单整合的。进一步，我想到了公司对于数据工程通道的标准，对数据能力要求涵盖了6个方面：准确性、完整性、及时性、安全性、合规性、一致性；想到这里，感觉更加一头雾水了。

再想，基于“世界上所有事情都有先例”这个思路，数据资产、类、分析框架这些东西存在相似性，那么它们肯定也有评价标准的思考，存在迁移性。那么回归本质，回归高维空间的理论，完美的数据架构需要满足：
- 熵守恒定律。总熵 = 业务熵 + 技术熵，而工程师需要保证技术熵不会随着时间过分的增加，尽量贴近于0、需要持续被压制。在数据资产场景中，指的是维护成本随着时间不能过分的增加；
- 正交分解原理。对维度的合理拆分，对维度的正交性验证、任意两维度变化互不干扰，对复合维度的封装。比如数据域的划分、表的维度的设计；
- 可逆性定理。抽象与具象的快速转换，比如在过度抽象时能快速具象化，在需求泛化时能无损抽象，对称性破缺检测、触发重构。比如资产要能快速实现需求，而需求又要能快速支持资产的迭代；

以上是deepseek所说的“元原则”，是复杂系统设计的底层逻辑，就像物理学中的能量守恒定律一样普适。而原则落地则千人千面，工程师实践的方法论就是如何做有原则的选择，在需求、技术力、成本三者之间做动态平衡。当面临具体业务场景的评估困惑时，可依次用这三个定律进行验证，任何优秀的设计必定同时满足以上三者。


# 使用元原则
以前我对于数据资产的设计，会有这些困惑，比如：
- 1、抽象层级不够，欠抽象：会导致资产表无法覆盖更多的需求
- 2、不够灵活，过抽象：资产表的变更很困难
- 3、让其他开发者可以简单的理解和使用

认识到元原则之后，发现1和2本质上是不满足可逆性原理；3是不满足熵守恒（理解熵）。至于在答辩时经常提到的技术术语，高可用、可扩展性、易用性等，都可以将它们回归到本质上去。数据资产设计的艺术在于找到业务确定性与不确定性的平衡点，而平衡点就是三条元原则。


# 完美架构的总结
最完美的数据架构是在业务演化速度、技术可实现性、成本约束条件构成的三维空间中，沿着最小作用量路径移动的动平衡态。其本质特征是：
- 在必要维度保持适当复杂度（如春节活动中引入Kafka实现削峰填谷）
- 在非核心路径极致简化（如用S3替代HDFS冷存储）
- 保留量子化跃迁能力（如通过FaaS快速响应业务突变）

最终目标不是消灭复杂度，而是让每个复杂度单位产生超过1.5倍的业务价值增益——这需要建立包含熵变监控、进化算法、量子评估的综合治理体系。

而对于三条元原则的理解，它们是罗盘，不是地图
- ​原则的确定性：像罗盘始终指向北方，商守恒/正交分解/可逆性揭示了系统设计的正确方向
- ​实践的灵活性：像水手需要根据风浪调整航线，工程师要根据业务阶段、团队能力、成本约束做出具体选择
- ​终极目标：通过原则的引导，在功能、质量、成本的铁三角中，找到当前上下文下的帕累托最优解​（没有绝对完美，只有当下最优），并非单纯的技术复杂度最小化

最终，伟大的工程师与普通开发者的区别，就在于能否在原则的确定性与实践的模糊性之间，走出优雅的平衡路径。


# 如何学习工程哲学
大模型的训练方式是暴力预训练+精调，采用的是Transformer模型；那么工程师学习工程哲学，也可以借鉴这种方式。

首先是暴力预训练，做广泛而密集的知识输入；然后对具体问题进行定向优化、微调。例如，每周都做知识漫游，同时将周边知识与主业联系起来，从而打造T型知识库（保持1-2个专业深度，维持3-5个知识广度）


# 从搬砖到学术
https://yuanbao.woa.com/bot/app/share/chat/e8d0ef8f7e0549ef54de728608027653  
在这里我问了元宝；距离来说，数据质量、数据资产化、元数据都是可能存在学术潜力的分支，但从日常工作抽象为理论、进而发表学术论文，一般可以经过以下几步：
- Step1: 问题抽象模板
    ```
    例如，将具体问题转化为学术问题：
    原始问题：数据血缘分析经常漏掉Hive临时表的关系
    转化公式：非持久化数据实体的跨系统追踪难题
    学术切口：瞬态数据对象的生命周期可观测性研究
    ```
- Step2: 工业数据科研化处理。对生产数据脱敏，抽取保留分布特性的小样本，数据增强
- Step3: 方法论创新模式库。从常用的工作技术、升级理论，比如从数据质量规则配置、升级为动态规则生成强化学习模型，从数据资产目录管理、升级为知识图谱驱动的元数据推荐系统
- ​Step4: 实验对比设计策略。通过实验对比说明理论创新的优越性

而常见的期刊有：
- VLDB/SIGMOD (侧重工程创新)
- KDD/ICML (侧重算法创新)
- IEEE Transactions on Knowledge and Data Engineering（跨学科类研究）
- 等等
